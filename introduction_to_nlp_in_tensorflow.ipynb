{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# What we're going to cover\n",
    "\n",
    "- Downloading a text dataset\n",
    "- Visualizing text data\n",
    "- Converting text into numbers using tokenization\n",
    "- Turning our tokenized text into an embedding\n",
    "- Modelling a text dataset\n",
    "    - Starting with a baseline (TF-IDF)\n",
    "    - Building several deep learning text models\n",
    "        - Dense, LSTM, GRU, Conv1D, Transfer learning\n",
    "- Comparing the performance of each our models\n",
    "- Combining our models into an ensemble\n",
    "- Saving and loading a trained model\n",
    "- Find the most wrong predictions"
   ],
   "id": "115c03481df181a5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:07.089920Z",
     "start_time": "2025-12-24T07:03:07.084557Z"
    }
   },
   "source": [
    "import datetime\n",
    "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last run (end-to-end): 2025-12-24 08:03:07.087558\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check for GPU",
   "id": "70a284f63ea0691f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:08.550338Z",
     "start_time": "2025-12-24T07:03:07.247536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ],
   "id": "755f9f137b67704d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA T500 (UUID: GPU-2e388ea4-5136-87e9-1d14-8e74849e1774)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get helper functions",
   "id": "936bf2bf50b81351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:08.765212Z",
     "start_time": "2025-12-24T07:03:08.570670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download helper functions script\n",
    "#!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
    "urllib.request.urlretrieve(url, \"helper_functions.py\")\n"
   ],
   "id": "d69b5a81110f0c60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('helper_functions.py', <http.client.HTTPMessage at 0x180c77a4140>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:14.041832Z",
     "start_time": "2025-12-24T07:03:08.779734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ],
   "id": "2f8ad4f16fafa893",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Download a text dataset from Kaggle",
   "id": "9b66333c08a08b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:14.952481Z",
     "start_time": "2025-12-24T07:03:14.055350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download data (same as from Kaggle)import urllib.request\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
    "urllib.request.urlretrieve(url, \"nlp_getting_started.zip\")\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"nlp_getting_started.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"nlp_getting_started\")  # folder where files will be extracted\n"
   ],
   "id": "7385ffdaad763b21",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizing a text dataset",
   "id": "3e0838c339179df2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.032810Z",
     "start_time": "2025-12-24T07:03:14.964533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Turn .csv files into pandas DataFrame's\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./nlp_getting_started/train.csv\")\n",
    "test_df = pd.read_csv(\"./nlp_getting_started/test.csv\")\n",
    "train_df.head()"
   ],
   "id": "3bb5425bcf1300ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.090510Z",
     "start_time": "2025-12-24T07:03:15.081191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ],
   "id": "b073a699cff78374",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.216738Z",
     "start_time": "2025-12-24T07:03:15.209920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The test data doesn't have a target (that's what we'd try to predict)\n",
    "test_df.head()"
   ],
   "id": "be78394f8c0abc8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.480363Z",
     "start_time": "2025-12-24T07:03:15.473367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ],
   "id": "96741c77ee704f73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since we have two target values, we're dealing with a binary classification problem.\n",
    "\n",
    "It's fairly balanced too, about 60% negative class (target = 0) and 40% positive class (target = 1).\n",
    "\n",
    "Where,\n",
    "- 1 = a real disaster Tweet\n",
    "- 0 = not a real disaster Tweet"
   ],
   "id": "d7aca07263302cae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.683821Z",
     "start_time": "2025-12-24T07:03:15.680631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ],
   "id": "84bc8acfca08d603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alright, seems like we've got a decent amount of training and test data. If anything, we've got an abundance of testing examples, usually a split of 90/10 (90% training, 10% testing) or 80/20 is suffice.",
   "id": "9fabae73ab411a6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.839754Z",
     "start_time": "2025-12-24T07:03:15.833455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ],
   "id": "1905fd2334bbc15b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "I-77 Mile Marker 31 to 40 South Mooresville  Iredell Vehicle Accident Congestion at 8/6 1:18 PM\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Also in a matter of weeks Amazon's going to be deluged with poorly written indie dystopian fiction about teens escaping from blood farms.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Captain Abbott must go down with LNP boat #refugees #christianvalues https://t.co/Kp5dpOaF58\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Crptotech tsunami and banks.\n",
      " http://t.co/KHzTeVeDja #Banking #tech #bitcoing #blockchain\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@briannafrost Twister with Bill Paxton and Helen Hunt!\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split data into training and validation sets",
   "id": "918f32b22ff087ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:15.979671Z",
     "start_time": "2025-12-24T07:03:15.957124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split                                                                (train_df_shuffled[\"text\"].to_numpy(),                                                        train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                random_state=42) # random state for reproducibility"
   ],
   "id": "ea0ededc452e5edf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.047142Z",
     "start_time": "2025-12-24T07:03:16.041817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ],
   "id": "420f57218fecdc0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.139509Z",
     "start_time": "2025-12-24T07:03:16.135353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ],
   "id": "4e3ef609a27e7260",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Converting text into numbers",
   "id": "b849efa556d072ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text vectorization (tokenization)",
   "id": "822b656ed4d9282f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.236800Z",
     "start_time": "2025-12-24T07:03:16.200642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
    "\n",
    "# Before TensorFlow 2.6\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ],
   "id": "7d8b62b9cbe21c84",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.266887Z",
     "start_time": "2025-12-24T07:03:16.256896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ],
   "id": "f62c37dbc921130d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.315175Z",
     "start_time": "2025-12-24T07:03:16.307090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ],
   "id": "55c2d21a0080e146",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.438230Z",
     "start_time": "2025-12-24T07:03:16.339634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ],
   "id": "e772fe14173c9ca3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:16.471178Z",
     "start_time": "2025-12-24T07:03:16.456183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ],
   "id": "ba4443658d956dbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:18.431956Z",
     "start_time": "2025-12-24T07:03:18.420812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ],
   "id": "186c37f399ccb8d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Short Reading\n",
      "\n",
      "Apocalypse 21:1023 \n",
      "\n",
      "In the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[1254, 1262,  409, 6339,    4,    2, 2286,    2, 1905, 1166,   31,\n",
       "           5,    2,  212,    6]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:18.573512Z",
     "start_time": "2025-12-24T07:03:18.549504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\")\n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ],
   "id": "acbcec29cda44912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', np.str_('the'), np.str_('a'), np.str_('in')]\n",
      "Bottom 5 least common words: [np.str_('pages'), np.str_('paeds'), np.str_('pads'), np.str_('padres'), np.str_('paddytomlinson1')]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating an Embedding using an Embedding Layer",
   "id": "4413687c3d2597da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:18.718544Z",
     "start_time": "2025-12-24T07:03:18.693647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\")\n",
    "\n",
    "embedding"
   ],
   "id": "3ad0378378107622",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Embedding name=embedding_1, built=False>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:18.908159Z",
     "start_time": "2025-12-24T07:03:18.830516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ],
   "id": "a2219b688bbe5f08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Rightways: Building structural integrity &amp; failure: problems inspections  repair http://t.co/vz1irH0Nmm via @rightwaystan      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04316019, -0.00167   , -0.02028508, ...,  0.01984495,\n",
       "         -0.04059559,  0.02704164],\n",
       "        [ 0.02275944, -0.01646917,  0.02050297, ...,  0.03229925,\n",
       "          0.01389399,  0.01895919],\n",
       "        [ 0.03753896,  0.0114907 , -0.00904044, ...,  0.01476774,\n",
       "         -0.0062887 , -0.00274624],\n",
       "        ...,\n",
       "        [ 0.02019395, -0.02619686,  0.03465054, ..., -0.02450359,\n",
       "          0.04955477, -0.04775412],\n",
       "        [ 0.02019395, -0.02619686,  0.03465054, ..., -0.02450359,\n",
       "          0.04955477, -0.04775412],\n",
       "        [ 0.02019395, -0.02619686,  0.03465054, ..., -0.02450359,\n",
       "          0.04955477, -0.04775412]]], shape=(1, 15, 128), dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:18.947953Z",
     "start_time": "2025-12-24T07:03:18.936675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ],
   "id": "d66371eb15fdb1ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-4.31601889e-02, -1.67000294e-03, -2.02850830e-02, -2.38582846e-02,\n",
       "        3.20721008e-02,  4.57740687e-02,  4.84046675e-02,  3.04718651e-02,\n",
       "       -1.00517273e-02,  1.09087825e-02,  4.14547659e-02,  5.47002628e-03,\n",
       "       -4.07205597e-02, -3.52407470e-02, -4.63708639e-02, -2.93159019e-02,\n",
       "        2.15597190e-02, -1.70132406e-02,  4.57748063e-02, -4.60485108e-02,\n",
       "       -4.84874733e-02, -1.78639404e-02, -2.78745648e-02,  4.86203283e-03,\n",
       "       -4.42596339e-02, -4.03559431e-02, -3.59393358e-02,  3.25220935e-02,\n",
       "        2.54580416e-02,  1.49445571e-02, -2.69644149e-02,  1.67481564e-02,\n",
       "        2.87892669e-03,  3.88235971e-03, -1.82765499e-02,  1.98431946e-02,\n",
       "        2.44675614e-02,  4.66184057e-02, -4.69373353e-02,  4.73769754e-03,\n",
       "        1.38275288e-02,  4.58797328e-02, -4.69243638e-02, -4.54580300e-02,\n",
       "       -3.46992128e-02, -2.90261582e-03,  2.50187851e-02,  2.49551423e-02,\n",
       "        3.05781402e-02,  4.90013845e-02,  4.64664735e-02, -4.83919308e-03,\n",
       "       -4.01542410e-02, -1.90218817e-02, -2.68526673e-02,  2.98197530e-02,\n",
       "       -7.66664743e-03,  1.73326395e-02,  4.35202196e-03,  2.19009034e-02,\n",
       "        2.43954323e-02,  4.99946363e-02,  3.85734178e-02,  3.17632444e-02,\n",
       "       -5.28355688e-03, -2.37132665e-02,  9.38909128e-03, -1.64480209e-02,\n",
       "        5.80390543e-03,  4.59151529e-02, -3.65044363e-02,  1.14740953e-02,\n",
       "       -7.69498199e-03,  2.62574069e-02,  2.28883736e-02,  4.01632451e-02,\n",
       "        9.79868323e-03,  2.26376206e-03, -2.95427926e-02, -7.38216564e-03,\n",
       "        6.30464405e-03,  2.82975547e-02, -1.59372091e-02,  1.21579878e-02,\n",
       "        9.48846340e-03,  4.99812514e-03,  1.26365535e-02, -2.28489563e-03,\n",
       "        4.39214706e-03, -9.16782767e-03, -1.82368532e-02, -1.10931173e-02,\n",
       "        1.64927132e-02, -1.29314288e-02,  4.64589931e-02, -2.54362822e-02,\n",
       "        3.80050205e-02,  2.35217325e-02, -1.81751624e-02,  3.54413502e-02,\n",
       "       -8.22137669e-03, -2.85486132e-03, -3.53640318e-03,  3.48750018e-02,\n",
       "       -3.62582915e-02, -3.16179916e-03,  8.16864893e-03, -1.56558864e-02,\n",
       "       -2.48881709e-02,  2.55102254e-02, -4.76898439e-02,  4.54682000e-02,\n",
       "        3.69247086e-02,  3.17116268e-02,  3.23656835e-02,  4.28402312e-02,\n",
       "       -4.05283459e-02,  2.36721076e-02,  2.86325812e-05, -2.69789938e-02,\n",
       "        2.04119347e-02, -3.27755436e-02,  2.31232755e-02,  1.35364570e-02,\n",
       "       -9.86237451e-03,  1.98449530e-02, -4.05955911e-02,  2.70416401e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Models:\n",
    "we'll be building the following:\n",
    "- Model 0: Naive Bayes (baseline)\n",
    "- Model 1: Feed-forward neural network (dense model)\n",
    "- Model 2: LSTM model\n",
    "- Model 3: GRU model\n",
    "- Model 4: Bidirectional-LSTM model\n",
    "- Model 5: 1D Convolutional Neural Network\n",
    "- Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
    "- Model 7: Same as model 6 with 10% of training data"
   ],
   "id": "cc8a1712b08aa21f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
    "\n",
    "Each experiment will go through the following steps:\n",
    "\n",
    "- Construct the model\n",
    "- Train the model\n",
    "- Make predictions with the model\n",
    "- Track prediction evaluation metrics for later comparison"
   ],
   "id": "8531e2813b0b29f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 0: Getting a baseline\n",
    "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert the words to numbers and then model them with the Multinomial Naive Bayes algorithm. This was chosen via referring to the Scikit-Learn machine learning map."
   ],
   "id": "e1aa8aa3da2f5871"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.215343Z",
     "start_time": "2025-12-24T07:03:18.987413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ],
   "id": "9e01963a0d3e9da4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;tfidf&#x27;, ...), (&#x27;clf&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"tfidf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=input,-%7B%27filename%27%2C%20%27file%27%2C%20%27content%27%7D%2C%20default%3D%27content%27\">\n",
       "            input\n",
       "            <span class=\"param-doc-description\">input: {'filename', 'file', 'content'}, default='content'<br><br>- If `'filename'`, the sequence passed as an argument to fit is<br>  expected to be a list of filenames that need reading to fetch<br>  the raw content to analyze.<br><br>- If `'file'`, the sequence items must have a 'read' method (file-like<br>  object) that is called to fetch the bytes in memory.<br><br>- If `'content'`, the input is expected to be a sequence of items that<br>  can be of type string or byte.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=encoding,-str%2C%20default%3D%27utf-8%27\">\n",
       "            encoding\n",
       "            <span class=\"param-doc-description\">encoding: str, default='utf-8'<br><br>If bytes or files are given to analyze, this encoding is used to<br>decode.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=decode_error,-%7B%27strict%27%2C%20%27ignore%27%2C%20%27replace%27%7D%2C%20default%3D%27strict%27\">\n",
       "            decode_error\n",
       "            <span class=\"param-doc-description\">decode_error: {'strict', 'ignore', 'replace'}, default='strict'<br><br>Instruction on what to do if a byte sequence is given to analyze that<br>contains characters not of the given `encoding`. By default, it is<br>'strict', meaning that a UnicodeDecodeError will be raised. Other<br>values are 'ignore' and 'replace'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=strip_accents,-%7B%27ascii%27%2C%20%27unicode%27%7D%20or%20callable%2C%20default%3DNone\">\n",
       "            strip_accents\n",
       "            <span class=\"param-doc-description\">strip_accents: {'ascii', 'unicode'} or callable, default=None<br><br>Remove accents and perform other character normalization<br>during the preprocessing step.<br>'ascii' is a fast method that only works on characters that have<br>a direct ASCII mapping.<br>'unicode' is a slightly slower method that works on any characters.<br>None (default) means no character normalization is performed.<br><br>Both 'ascii' and 'unicode' use NFKD normalization from<br>:func:`unicodedata.normalize`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=lowercase,-bool%2C%20default%3DTrue\">\n",
       "            lowercase\n",
       "            <span class=\"param-doc-description\">lowercase: bool, default=True<br><br>Convert all characters to lowercase before tokenizing.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=preprocessor,-callable%2C%20default%3DNone\">\n",
       "            preprocessor\n",
       "            <span class=\"param-doc-description\">preprocessor: callable, default=None<br><br>Override the preprocessing (string transformation) stage while<br>preserving the tokenizing and n-grams generation steps.<br>Only applies if ``analyzer`` is not callable.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=tokenizer,-callable%2C%20default%3DNone\">\n",
       "            tokenizer\n",
       "            <span class=\"param-doc-description\">tokenizer: callable, default=None<br><br>Override the string tokenization step while preserving the<br>preprocessing and n-grams generation steps.<br>Only applies if ``analyzer == 'word'``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=analyzer,-%7B%27word%27%2C%20%27char%27%2C%20%27char_wb%27%7D%20or%20callable%2C%20default%3D%27word%27\">\n",
       "            analyzer\n",
       "            <span class=\"param-doc-description\">analyzer: {'word', 'char', 'char_wb'} or callable, default='word'<br><br>Whether the feature should be made of word or character n-grams.<br>Option 'char_wb' creates character n-grams only from text inside<br>word boundaries; n-grams at the edges of words are padded with space.<br><br>If a callable is passed it is used to extract the sequence of features<br>out of the raw, unprocessed input.<br><br>.. versionchanged:: 0.21<br>    Since v0.21, if ``input`` is ``'filename'`` or ``'file'``, the data<br>    is first read from the file and then passed to the given callable<br>    analyzer.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=stop_words,-%7B%27english%27%7D%2C%20list%2C%20default%3DNone\">\n",
       "            stop_words\n",
       "            <span class=\"param-doc-description\">stop_words: {'english'}, list, default=None<br><br>If a string, it is passed to _check_stop_list and the appropriate stop<br>list is returned. 'english' is currently the only supported string<br>value.<br>There are several known issues with 'english' and you should<br>consider an alternative (see :ref:`stop_words`).<br><br>If a list, that list is assumed to contain stop words, all of which<br>will be removed from the resulting tokens.<br>Only applies if ``analyzer == 'word'``.<br><br>If None, no stop words will be used. In this case, setting `max_df`<br>to a higher value, such as in the range (0.7, 1.0), can automatically detect<br>and filter stop words based on intra corpus document frequency of terms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=token_pattern,-str%2C%20default%3Dr%22%28%3Fu%29%5C%5Cb%5C%5Cw%5C%5Cw%2B%5C%5Cb%22\">\n",
       "            token_pattern\n",
       "            <span class=\"param-doc-description\">token_pattern: str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"<br><br>Regular expression denoting what constitutes a \"token\", only used<br>if ``analyzer == 'word'``. The default regexp selects tokens of 2<br>or more alphanumeric characters (punctuation is completely ignored<br>and always treated as a token separator).<br><br>If there is a capturing group in token_pattern then the<br>captured group content, not the entire match, becomes the token.<br>At most one capturing group is permitted.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=ngram_range,-tuple%20%28min_n%2C%20max_n%29%2C%20default%3D%281%2C%201%29\">\n",
       "            ngram_range\n",
       "            <span class=\"param-doc-description\">ngram_range: tuple (min_n, max_n), default=(1, 1)<br><br>The lower and upper boundary of the range of n-values for different<br>n-grams to be extracted. All values of n such that min_n <= n <= max_n<br>will be used. For example an ``ngram_range`` of ``(1, 1)`` means only<br>unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means<br>only bigrams.<br>Only applies if ``analyzer`` is not callable.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=max_df,-float%20or%20int%2C%20default%3D1.0\">\n",
       "            max_df\n",
       "            <span class=\"param-doc-description\">max_df: float or int, default=1.0<br><br>When building the vocabulary ignore terms that have a document<br>frequency strictly higher than the given threshold (corpus-specific<br>stop words).<br>If float in range [0.0, 1.0], the parameter represents a proportion of<br>documents, integer absolute counts.<br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=min_df,-float%20or%20int%2C%20default%3D1\">\n",
       "            min_df\n",
       "            <span class=\"param-doc-description\">min_df: float or int, default=1<br><br>When building the vocabulary ignore terms that have a document<br>frequency strictly lower than the given threshold. This value is also<br>called cut-off in the literature.<br>If float in range of [0.0, 1.0], the parameter represents a proportion<br>of documents, integer absolute counts.<br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=max_features,-int%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, default=None<br><br>If not None, build a vocabulary that only consider the top<br>`max_features` ordered by term frequency across the corpus.<br>Otherwise, all features are used.<br><br>This parameter is ignored if vocabulary is not None.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=vocabulary,-Mapping%20or%20iterable%2C%20default%3DNone\">\n",
       "            vocabulary\n",
       "            <span class=\"param-doc-description\">vocabulary: Mapping or iterable, default=None<br><br>Either a Mapping (e.g., a dict) where keys are terms and values are<br>indices in the feature matrix, or an iterable over terms. If not<br>given, a vocabulary is determined from the input documents.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=binary,-bool%2C%20default%3DFalse\">\n",
       "            binary\n",
       "            <span class=\"param-doc-description\">binary: bool, default=False<br><br>If True, all non-zero term counts are set to 1. This does not mean<br>outputs will have only 0/1 values, only that the tf term in tf-idf<br>is binary. (Set `binary` to True, `use_idf` to False and<br>`norm` to None to get 0/1 outputs).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=dtype,-dtype%2C%20default%3Dfloat64\">\n",
       "            dtype\n",
       "            <span class=\"param-doc-description\">dtype: dtype, default=float64<br><br>Type of the matrix returned by fit_transform() or transform().</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=norm,-%7B%27l1%27%2C%20%27l2%27%7D%20or%20None%2C%20default%3D%27l2%27\">\n",
       "            norm\n",
       "            <span class=\"param-doc-description\">norm: {'l1', 'l2'} or None, default='l2'<br><br>Each output row will have unit norm, either:<br><br>- 'l2': Sum of squares of vector elements is 1. The cosine<br>  similarity between two vectors is their dot product when l2 norm has<br>  been applied.<br>- 'l1': Sum of absolute values of vector elements is 1.<br>  See :func:`~sklearn.preprocessing.normalize`.<br>- None: No normalization.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=use_idf,-bool%2C%20default%3DTrue\">\n",
       "            use_idf\n",
       "            <span class=\"param-doc-description\">use_idf: bool, default=True<br><br>Enable inverse-document-frequency reweighting. If False, idf(t) = 1.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=smooth_idf,-bool%2C%20default%3DTrue\">\n",
       "            smooth_idf\n",
       "            <span class=\"param-doc-description\">smooth_idf: bool, default=True<br><br>Smooth idf weights by adding one to document frequencies, as if an<br>extra document was seen containing every term in the collection<br>exactly once. Prevents zero divisions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#:~:text=sublinear_tf,-bool%2C%20default%3DFalse\">\n",
       "            sublinear_tf\n",
       "            <span class=\"param-doc-description\">sublinear_tf: bool, default=False<br><br>Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"clf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=alpha,-float%20or%20array-like%20of%20shape%20%28n_features%2C%29%2C%20default%3D1.0\">\n",
       "            alpha\n",
       "            <span class=\"param-doc-description\">alpha: float or array-like of shape (n_features,), default=1.0<br><br>Additive (Laplace/Lidstone) smoothing parameter<br>(set alpha=0 and force_alpha=True, for no smoothing).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('force_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=force_alpha,-bool%2C%20default%3DTrue\">\n",
       "            force_alpha\n",
       "            <span class=\"param-doc-description\">force_alpha: bool, default=True<br><br>If False and alpha is less than 1e-10, it will set alpha to<br>1e-10. If True, alpha will remain unchanged. This may cause<br>numerical errors if alpha is too close to 0.<br><br>.. versionadded:: 1.2<br>.. versionchanged:: 1.4<br>   The default value of `force_alpha` changed to `True`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=fit_prior,-bool%2C%20default%3DTrue\">\n",
       "            fit_prior\n",
       "            <span class=\"param-doc-description\">fit_prior: bool, default=True<br><br>Whether to learn class prior probabilities or not.<br>If false, a uniform prior will be used.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=class_prior,-array-like%20of%20shape%20%28n_classes%2C%29%2C%20default%3DNone\">\n",
       "            class_prior\n",
       "            <span class=\"param-doc-description\">class_prior: array-like of shape (n_classes,), default=None<br><br>Prior probabilities of the classes. If specified, the priors are not<br>adjusted according to the data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.273863Z",
     "start_time": "2025-12-24T07:03:19.255865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ],
   "id": "d3ad9fe0f0734991",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.313344Z",
     "start_time": "2025-12-24T07:03:19.299255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ],
   "id": "6bb20b324e670117",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating an evaluation function for model experiments\n",
    "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score"
   ],
   "id": "86b1f8f0a24b39af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.353044Z",
     "start_time": "2025-12-24T07:03:19.349572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ],
   "id": "c4d011c33275d1b9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.402936Z",
     "start_time": "2025-12-24T07:03:19.395564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ],
   "id": "2547f2876bbe6153",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.477623Z",
     "start_time": "2025-12-24T07:03:19.474536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ],
   "id": "ae0addfe1aa3c778",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model 1: A simple dense model",
   "id": "4a6755a2de02e681"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.539430Z",
     "start_time": "2025-12-24T07:03:19.520619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ],
   "id": "46fae6e81985b5ef",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.583036Z",
     "start_time": "2025-12-24T07:03:19.569944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "id": "b6daf3714ece286e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:19.623877Z",
     "start_time": "2025-12-24T07:03:19.604837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a summary of the model\n",
    "model_1.summary()"
   ],
   "id": "4401817d7937b13e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_1_dense\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1_dense\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling1D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,280,129\u001B[0m (4.88 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,280,129\u001B[0m (4.88 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:27.421601Z",
     "start_time": "2025-12-24T07:03:19.674800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"simple_dense_model\")])"
   ],
   "id": "b96ef63656885d48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20251224-080319\n",
      "Epoch 1/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.6923 - loss: 0.6062 - val_accuracy: 0.7612 - val_loss: 0.5336\n",
      "Epoch 2/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8159 - loss: 0.4426 - val_accuracy: 0.7861 - val_loss: 0.4738\n",
      "Epoch 3/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8580 - loss: 0.3500 - val_accuracy: 0.7927 - val_loss: 0.4618\n",
      "Epoch 4/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8891 - loss: 0.2876 - val_accuracy: 0.7874 - val_loss: 0.4680\n",
      "Epoch 5/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9096 - loss: 0.2408 - val_accuracy: 0.7795 - val_loss: 0.4837\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:27.536343Z",
     "start_time": "2025-12-24T07:03:27.441123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ],
   "id": "38edceb9600cf752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7795 - loss: 0.4837 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4837081730365753, 0.7795275449752808]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:27.574199Z",
     "start_time": "2025-12-24T07:03:27.556472Z"
    }
   },
   "cell_type": "code",
   "source": "embedding.weights",
   "id": "364a629f4b1f2974",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=embedding_1/embeddings, shape=(10000, 128), dtype=float32, value=[[ 0.02972109 -0.03425552  0.02204993 ... -0.0158638   0.05495876\n",
       "   -0.03391934]\n",
       "  [-0.02769216 -0.05828141  0.01119315 ... -0.00816636 -0.00691805\n",
       "    0.00601563]\n",
       "  [ 0.00420488  0.0274639  -0.02206638 ...  0.02352214  0.00949598\n",
       "    0.02243589]\n",
       "  ...\n",
       "  [ 0.00170995 -0.0298877   0.00097704 ...  0.02391691  0.02477095\n",
       "   -0.04653875]\n",
       "  [ 0.03470577 -0.04540648 -0.00699639 ...  0.05866688  0.00327083\n",
       "    0.02194152]\n",
       "  [ 0.10286075 -0.0795557  -0.06038719 ...  0.0863701   0.08320185\n",
       "    0.02508597]]>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:27.622979Z",
     "start_time": "2025-12-24T07:03:27.617997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ],
   "id": "f9fa237692da37e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.112232Z",
     "start_time": "2025-12-24T07:03:27.749926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ],
   "id": "a3f84d4fdd0fe5dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32895583],\n",
       "       [0.73381984],\n",
       "       [0.9976628 ],\n",
       "       [0.18897177],\n",
       "       [0.09918014],\n",
       "       [0.9447549 ],\n",
       "       [0.88734657],\n",
       "       [0.9941373 ],\n",
       "       [0.96245146],\n",
       "       [0.39148343]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.222106Z",
     "start_time": "2025-12-24T07:03:28.203116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ],
   "id": "d2df59ee3c6c12a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.465718Z",
     "start_time": "2025-12-24T07:03:28.447322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ],
   "id": "ff7945cbf2ef3507",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7829461349391948,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7768651797484591}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.603508Z",
     "start_time": "2025-12-24T07:03:28.595507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Is our simple Keras model better than our baseline model?\n",
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ],
   "id": "c075e123eb889407",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.745481Z",
     "start_time": "2025-12-24T07:03:28.738465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
    "                                new_model_results=model_1_results)"
   ],
   "id": "e73ba17b42bdfa4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.95, Difference: -1.31\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizing learned embeddings",
   "id": "15c7c11e163da6fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:28.930379Z",
     "start_time": "2025-12-24T07:03:28.876353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ],
   "id": "7ba7abe57dac2ac6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['',\n",
       "  '[UNK]',\n",
       "  np.str_('the'),\n",
       "  np.str_('a'),\n",
       "  np.str_('in'),\n",
       "  np.str_('to'),\n",
       "  np.str_('of'),\n",
       "  np.str_('and'),\n",
       "  np.str_('i'),\n",
       "  np.str_('is')])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:29.045645Z",
     "start_time": "2025-12-24T07:03:29.007893Z"
    }
   },
   "cell_type": "code",
   "source": "model_1.summary()",
   "id": "d92707d55da23a9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_1_dense\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1_dense\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling1D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3,840,389\u001B[0m (14.65 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,389</span> (14.65 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,280,129\u001B[0m (4.88 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m2,560,260\u001B[0m (9.77 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,260</span> (9.77 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:29.297276Z",
     "start_time": "2025-12-24T07:03:29.284471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
   ],
   "id": "1a89cc413e22f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Recurrent Neural Networks (RNN's)\n",
    "\n",
    "- Long short-term memory cells (LSTMs).\n",
    "- Gated recurrent units (GRUs).\n",
    "- Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n"
   ],
   "id": "6cb349335fbc3fbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- One to one: one input, one output, such as image classification.\n",
    "- One to many: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
    "- Many to one: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
    "- Many to many: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output)."
   ],
   "id": "bef2ff2b0d0de0bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 2: LSTM\n",
    "\n",
    "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
   ],
   "id": "8fb530c1c9ec7cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:29.529607Z",
     "start_time": "2025-12-24T07:03:29.391313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_2\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ],
   "id": "16333ced0650a30a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:29.597638Z",
     "start_time": "2025-12-24T07:03:29.580092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "id": "16f406a3e9a85aee",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:29.650420Z",
     "start_time": "2025-12-24T07:03:29.634461Z"
    }
   },
   "cell_type": "code",
   "source": "model_2.summary()",
   "id": "1f7bdb3c50f39c0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_2_LSTM\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2_LSTM\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │        \u001B[38;5;34m49,408\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m65\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,329,473\u001B[0m (5.07 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,329,473\u001B[0m (5.07 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:50.923593Z",
     "start_time": "2025-12-24T07:03:29.771313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"LSTM\")])"
   ],
   "id": "a45968eef8988dcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20251224-080329\n",
      "Epoch 1/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 19ms/step - accuracy: 0.7415 - loss: 0.5118 - val_accuracy: 0.7743 - val_loss: 0.4613\n",
      "Epoch 2/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.8710 - loss: 0.3135 - val_accuracy: 0.7638 - val_loss: 0.5138\n",
      "Epoch 3/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - accuracy: 0.9206 - loss: 0.2152 - val_accuracy: 0.7520 - val_loss: 0.6294\n",
      "Epoch 4/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - accuracy: 0.9508 - loss: 0.1500 - val_accuracy: 0.7520 - val_loss: 0.6711\n",
      "Epoch 5/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - accuracy: 0.9606 - loss: 0.1173 - val_accuracy: 0.7690 - val_loss: 0.6727\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:51.765635Z",
     "start_time": "2025-12-24T07:03:50.969374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ],
   "id": "b4f809d7e8bde061",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.02722836],\n",
       "        [0.9462813 ],\n",
       "        [0.99778634],\n",
       "        [0.05585869],\n",
       "        [0.00578585],\n",
       "        [0.9921038 ],\n",
       "        [0.17700574],\n",
       "        [0.9996012 ],\n",
       "        [0.9984145 ],\n",
       "        [0.47728023]], dtype=float32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:51.819907Z",
     "start_time": "2025-12-24T07:03:51.808050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ],
   "id": "18f858f5d33d675b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:51.912106Z",
     "start_time": "2025-12-24T07:03:51.900955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ],
   "id": "6ec2752f7159937d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'precision': 0.772410916855732,\n",
       " 'recall': 0.7690288713910761,\n",
       " 'f1': 0.7660901868079131}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:51.992249Z",
     "start_time": "2025-12-24T07:03:51.988378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ],
   "id": "873fc61ae0a2a6e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.90, Difference: -2.36\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 3: GRU\n",
    "- The GRU cell has similar features to an LSTM cell but has less parameters."
   ],
   "id": "42185f763bb4120c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:52.178575Z",
     "start_time": "2025-12-24T07:03:52.070107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ],
   "id": "5138259fcc673e9d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:52.295893Z",
     "start_time": "2025-12-24T07:03:52.274364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "id": "7dd3baa86a817ede",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:03:52.376918Z",
     "start_time": "2025-12-24T07:03:52.345020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a summary of the GRU model\n",
    "model_3.summary()"
   ],
   "id": "5bbf3646597bcedb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_3_GRU\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_GRU\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001B[38;5;33mGRU\u001B[0m)                       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │        \u001B[38;5;34m37,248\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m65\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,317,313\u001B[0m (5.03 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,313</span> (5.03 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,317,313\u001B[0m (5.03 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,313</span> (5.03 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notice the difference in number of trainable parameters between model_2 (LSTM) and model_3 (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.",
   "id": "a91217008ffd71f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:13.466156Z",
     "start_time": "2025-12-24T07:03:52.521088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
   ],
   "id": "4496624a26237b95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20251224-080352\n",
      "Epoch 1/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 18ms/step - accuracy: 0.7313 - loss: 0.5238 - val_accuracy: 0.7769 - val_loss: 0.4581\n",
      "Epoch 2/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 16ms/step - accuracy: 0.8718 - loss: 0.3124 - val_accuracy: 0.7677 - val_loss: 0.5141\n",
      "Epoch 3/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 16ms/step - accuracy: 0.9188 - loss: 0.2157 - val_accuracy: 0.7651 - val_loss: 0.5625\n",
      "Epoch 4/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - accuracy: 0.9426 - loss: 0.1613 - val_accuracy: 0.7717 - val_loss: 0.5928\n",
      "Epoch 5/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - accuracy: 0.9588 - loss: 0.1272 - val_accuracy: 0.7730 - val_loss: 0.6770\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.369892Z",
     "start_time": "2025-12-24T07:04:13.509895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ],
   "id": "c28532f6458573c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.05089664],\n",
       "        [0.8824475 ],\n",
       "        [0.9958301 ],\n",
       "        [0.08076845],\n",
       "        [0.01224369],\n",
       "        [0.9924836 ],\n",
       "        [0.27088422],\n",
       "        [0.99799764],\n",
       "        [0.9969034 ],\n",
       "        [0.791573  ]], dtype=float32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.466686Z",
     "start_time": "2025-12-24T07:04:14.455680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ],
   "id": "4d641a3a2fe14bb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.566757Z",
     "start_time": "2025-12-24T07:04:14.554690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ],
   "id": "909ca4ee7ef0d3b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.29658792650919,\n",
       " 'precision': 0.7774632689285239,\n",
       " 'recall': 0.7729658792650919,\n",
       " 'f1': 0.7696944315968833}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.630697Z",
     "start_time": "2025-12-24T07:04:14.626231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ],
   "id": "55af437c950a6aa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 4: Bidirectonal RNN model\n",
    "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left."
   ],
   "id": "ce41b21f1899d790"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.797812Z",
     "start_time": "2025-12-24T07:04:14.711716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ],
   "id": "85374ebba56b0f25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.901821Z",
     "start_time": "2025-12-24T07:04:14.876869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "id": "899cad0476cc6d25",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:14.994135Z",
     "start_time": "2025-12-24T07:04:14.974859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get a summary of our bidirectional model\n",
    "model_4.summary()"
   ],
   "id": "d7e9e25bbf67d264",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_4_Bidirectional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_4_Bidirectional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m98,816\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,378,945\u001B[0m (5.26 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,378,945\u001B[0m (5.26 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:36.400188Z",
     "start_time": "2025-12-24T07:04:15.131335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
   ],
   "id": "dbaadaa84b167b51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20251224-080415\n",
      "Epoch 1/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 19ms/step - accuracy: 0.7460 - loss: 0.5115 - val_accuracy: 0.7822 - val_loss: 0.4621\n",
      "Epoch 2/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.8720 - loss: 0.3120 - val_accuracy: 0.7703 - val_loss: 0.4984\n",
      "Epoch 3/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - accuracy: 0.9244 - loss: 0.2063 - val_accuracy: 0.7559 - val_loss: 0.5810\n",
      "Epoch 4/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.9553 - loss: 0.1352 - val_accuracy: 0.7559 - val_loss: 0.6867\n",
      "Epoch 5/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - accuracy: 0.9635 - loss: 0.1132 - val_accuracy: 0.7323 - val_loss: 0.7752\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:37.476057Z",
     "start_time": "2025-12-24T07:04:36.482087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ],
   "id": "4cc395c10488e5a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41730875],\n",
       "       [0.9528347 ],\n",
       "       [0.9996913 ],\n",
       "       [0.13248971],\n",
       "       [0.01178824],\n",
       "       [0.99495125],\n",
       "       [0.96676195],\n",
       "       [0.99988085],\n",
       "       [0.9995078 ],\n",
       "       [0.82138956]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:37.590944Z",
     "start_time": "2025-12-24T07:04:37.581444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ],
   "id": "852341e14bbc98ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:37.778145Z",
     "start_time": "2025-12-24T07:04:37.761794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ],
   "id": "caf3e30bea157856",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.22834645669292,\n",
       " 'precision': 0.732063549361326,\n",
       " 'recall': 0.7322834645669292,\n",
       " 'f1': 0.7321532667187165}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:37.897775Z",
     "start_time": "2025-12-24T07:04:37.891511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check to see how the bidirectional model performs against the baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ],
   "id": "ed37d56a0450ca73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 73.23, Difference: -6.04\n",
      "Baseline precision: 0.81, New precision: 0.73, Difference: -0.08\n",
      "Baseline recall: 0.79, New recall: 0.73, Difference: -0.06\n",
      "Baseline f1: 0.79, New f1: 0.73, Difference: -0.05\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Networks for Text\n",
    "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
    "\n",
    "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
    "\n",
    "A typical CNN architecture for sequences will look like the following:\n",
    "\n",
    "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)"
   ],
   "id": "fb1fb9cee4df0a0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model 5: Conv1D\n",
    "Conv1D() layer and GlobalMaxPool1D()"
   ],
   "id": "48fd94adff701482"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:38.120739Z",
     "start_time": "2025-12-24T07:04:38.016905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test out the embedding, 1D convolutional and max pooling\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
    "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
    "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ],
   "id": "1bb5f0cc164a9e11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:38.265548Z",
     "start_time": "2025-12-24T07:04:38.251636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See the outputs of each layer\n",
    "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
   ],
   "id": "e5fb48fb0a8dff20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       " array([[[ 0.03413655,  0.04470034, -0.01593568, ..., -0.02553193,\n",
       "           0.0175904 , -0.03492376],\n",
       "         [ 0.05649506, -0.04608185, -0.00410373, ...,  0.08498462,\n",
       "           0.0030562 ,  0.00337665],\n",
       "         [ 0.02171097,  0.02538986, -0.0458759 , ...,  0.05268139,\n",
       "           0.04048828,  0.00727649],\n",
       "         ...,\n",
       "         [ 0.02972109, -0.03425552,  0.02204993, ..., -0.0158638 ,\n",
       "           0.05495876, -0.03391934],\n",
       "         [ 0.02972109, -0.03425552,  0.02204993, ..., -0.0158638 ,\n",
       "           0.05495876, -0.03391934],\n",
       "         [ 0.02972109, -0.03425552,  0.02204993, ..., -0.0158638 ,\n",
       "           0.05495876, -0.03391934]]], shape=(1, 15, 128), dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       " array([[[0.00820213, 0.10106147, 0.060546  , 0.        , 0.02913955,\n",
       "          0.00822927, 0.00984483, 0.        , 0.        , 0.        ,\n",
       "          0.02405586, 0.        , 0.        , 0.00265213, 0.        ,\n",
       "          0.        , 0.01315029, 0.06103165, 0.04716082, 0.03663391,\n",
       "          0.04397418, 0.        , 0.03449998, 0.        , 0.        ,\n",
       "          0.        , 0.02927161, 0.10799675, 0.        , 0.        ,\n",
       "          0.05516937, 0.        ],\n",
       "         [0.        , 0.02255799, 0.00428901, 0.        , 0.        ,\n",
       "          0.0182813 , 0.        , 0.        , 0.00620881, 0.        ,\n",
       "          0.02279096, 0.        , 0.        , 0.02782887, 0.        ,\n",
       "          0.        , 0.01377791, 0.04459023, 0.00088352, 0.        ,\n",
       "          0.        , 0.02329266, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.03115788, 0.08316447, 0.05161954,\n",
       "          0.00846944, 0.        ],\n",
       "         [0.00226388, 0.01872768, 0.00775248, 0.        , 0.01227216,\n",
       "          0.07494204, 0.06240006, 0.        , 0.        , 0.06047124,\n",
       "          0.        , 0.0363602 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.01110611, 0.0804639 , 0.        , 0.02486029,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.02168952, 0.        , 0.09340017, 0.0825506 , 0.00605274,\n",
       "          0.07054727, 0.1059866 ],\n",
       "         [0.        , 0.        , 0.04781441, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.10844085,\n",
       "          0.04572852, 0.01536789, 0.        , 0.01428542, 0.        ,\n",
       "          0.        , 0.09724563, 0.07642435, 0.        , 0.        ,\n",
       "          0.        , 0.02396353, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.04341517, 0.05809192, 0.0132475 ,\n",
       "          0.06681616, 0.        ],\n",
       "         [0.        , 0.03634124, 0.03256941, 0.00180956, 0.01155821,\n",
       "          0.04810144, 0.        , 0.        , 0.        , 0.02774058,\n",
       "          0.01519867, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.10056897, 0.02295636, 0.        , 0.02168209,\n",
       "          0.        , 0.0136904 , 0.02992649, 0.01677   , 0.03004641,\n",
       "          0.03764153, 0.        , 0.03454906, 0.0296375 , 0.01359363,\n",
       "          0.        , 0.00307095],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025],\n",
       "         [0.        , 0.02593801, 0.03808786, 0.        , 0.        ,\n",
       "          0.0280308 , 0.        , 0.00999323, 0.00030258, 0.03689813,\n",
       "          0.01101137, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07026693, 0.0321542 , 0.        , 0.        ,\n",
       "          0.        , 0.02873311, 0.03039499, 0.00440204, 0.04611047,\n",
       "          0.05075162, 0.        , 0.03211744, 0.06268397, 0.03304652,\n",
       "          0.03056252, 0.00913025]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[0.00820213, 0.10106147, 0.060546  , 0.00180956, 0.02913955,\n",
       "         0.07494204, 0.06240006, 0.00999323, 0.00620881, 0.10844085,\n",
       "         0.04572852, 0.0363602 , 0.        , 0.02782887, 0.        ,\n",
       "         0.        , 0.10056897, 0.0804639 , 0.04716082, 0.03663391,\n",
       "         0.04397418, 0.02873311, 0.03449998, 0.01677   , 0.04611047,\n",
       "         0.05075162, 0.02927161, 0.10799675, 0.08316447, 0.05161954,\n",
       "         0.07054727, 0.1059866 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:38.480394Z",
     "start_time": "2025-12-24T07:04:38.386820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_5\")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary of our 1D convolution model\n",
    "model_5.summary()"
   ],
   "id": "746badedceb2d01d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"model_5_Conv1D\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_5_Conv1D\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTextVectorization\u001B[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,280,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001B[38;5;33mConv1D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m11\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │        \u001B[38;5;34m20,512\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalMaxPooling1D\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,300,545\u001B[0m (4.96 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,300,545</span> (4.96 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,300,545\u001B[0m (4.96 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,300,545</span> (4.96 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:52.055948Z",
     "start_time": "2025-12-24T07:04:38.684743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"Conv1D\")])"
   ],
   "id": "36d146d64029930e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20251224-080438\n",
      "Epoch 1/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 12ms/step - accuracy: 0.7170 - loss: 0.5636 - val_accuracy: 0.7822 - val_loss: 0.4700\n",
      "Epoch 2/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.8635 - loss: 0.3385 - val_accuracy: 0.7835 - val_loss: 0.4760\n",
      "Epoch 3/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9242 - loss: 0.2109 - val_accuracy: 0.7808 - val_loss: 0.5287\n",
      "Epoch 4/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.9558 - loss: 0.1357 - val_accuracy: 0.7795 - val_loss: 0.5972\n",
      "Epoch 5/5\n",
      "\u001B[1m215/215\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.9689 - loss: 0.0959 - val_accuracy: 0.7795 - val_loss: 0.6604\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:52.607664Z",
     "start_time": "2025-12-24T07:04:52.143040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ],
   "id": "d5c930912c7ab467",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m24/24\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4880211 ],\n",
       "       [0.71613085],\n",
       "       [0.99970895],\n",
       "       [0.0882895 ],\n",
       "       [0.00718511],\n",
       "       [0.99857   ],\n",
       "       [0.9576286 ],\n",
       "       [0.9992597 ],\n",
       "       [0.9991296 ],\n",
       "       [0.16324525]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:52.754711Z",
     "start_time": "2025-12-24T07:04:52.742625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ],
   "id": "5934616d028e3636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:52.876752Z",
     "start_time": "2025-12-24T07:04:52.863119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate model_5 evaluation metrics\n",
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ],
   "id": "f44c3fb811252b67",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7841069305867823,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7764267379950773}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:04:53.021543Z",
     "start_time": "2025-12-24T07:04:53.016206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare model_5 results to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ],
   "id": "b4a7a1c6e235baf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.95, Difference: -1.31\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Pretrained Embeddings (transfer learning for NLP)\n",
    "## Model 6: TensorFlow Hub Pretrained Sentence Encoder"
   ],
   "id": "3418923df0df096"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:22:53.328684Z",
     "start_time": "2025-12-24T08:22:46.294689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model\n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\")"
   ],
   "id": "c9e22c0cec387cb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:30:59.590070Z",
     "start_time": "2025-12-24T08:30:59.475565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create model using the Sequential API\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import tf_keras as keras  # Use tf_keras instead of tensorflow.keras\n",
    "\n",
    "# 2. Build the model using tf_keras components\n",
    "model_6 = keras.Sequential([\n",
    "  sentence_encoder_layer,\n",
    "  keras.layers.Dense(64, activation=\"relu\"),\n",
    "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# 3. Compile using tf_keras optimizers\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ],
   "id": "dd0b26ebc90f921d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:33:14.839882Z",
     "start_time": "2025-12-24T08:33:06.835180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))#,\n",
    "                              #callbacks=[create_tensorboard_callback(SAVE_DIR,\"tf_hub_sentence_encoder\")])"
   ],
   "id": "7f1c30f4cad276a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdsan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 3s 7ms/step - loss: 0.5040 - accuracy: 0.7888 - val_loss: 0.4489 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8130 - val_loss: 0.4374 - val_accuracy: 0.8097\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4012 - accuracy: 0.8209 - val_loss: 0.4331 - val_accuracy: 0.8084\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3943 - accuracy: 0.8243 - val_loss: 0.4282 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3884 - accuracy: 0.8278 - val_loss: 0.4296 - val_accuracy: 0.8163\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:35:13.736015Z",
     "start_time": "2025-12-24T08:35:13.304018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ],
   "id": "c6d63eb4cf36ed90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15104501],\n",
       "       [0.7475632 ],\n",
       "       [0.9859173 ],\n",
       "       [0.22033809],\n",
       "       [0.74281776],\n",
       "       [0.6753238 ],\n",
       "       [0.980023  ],\n",
       "       [0.9710747 ],\n",
       "       [0.9254032 ],\n",
       "       [0.09494348]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:35:58.459666Z",
     "start_time": "2025-12-24T08:35:58.453668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ],
   "id": "238807d9cf35a140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:36:11.701570Z",
     "start_time": "2025-12-24T08:36:11.693567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ],
   "id": "40809d0ee9dbd7ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:36:44.498259Z",
     "start_time": "2025-12-24T08:36:44.494225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ],
   "id": "1aff982af4f7016d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.63, Difference: 2.36\n",
      "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
      "Baseline recall: 0.79, New recall: 0.82, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.81, Difference: 0.03\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c2f24ebbbd64501"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
